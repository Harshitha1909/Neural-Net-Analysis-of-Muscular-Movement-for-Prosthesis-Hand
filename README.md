# Neural-Net-Analysis-of-Muscular-Movement-for-Prosthesis-Hand
Abstract:
The project is a initiative aimed at significantly enhancing the quality of life for physically handicapped individuals who rely on prosthetic hands. We leverage real-time myoelectric interfaces, specifically surface electromyography, to capture and analyze muscular activity data associated with prosthetic hand movements in multiple dimensions, including the X, Y, and Z directions, as well as angular movements in both clockwise and anticlockwise directions. This comprehensive dataset serves as the foundation for our innovative approach to estimating the overall movement of prosthetic hands. Our methodology involves the integration of advanced machine learning techniques, such as Gaussian Naive Bayes (GNB) classification and Neural Network analysis. It comprises four integral modules aimed at revolutionizing prosthetic hand control for individuals with physical disabilities. The first module focuses on constructing and evaluating the Gaussian Naive Bayes (GNB) model to interpret myoelectric interface data accurately. Following this, the second module utilizes the GNB model for real-time predictions of prosthetic hand movements. Concurrently, the third module involves the development of a Neural Network model to further enhance prediction accuracy. Finally, the fourth module integrates the Neural Network into the system, enabling precise and intuitive control based on muscular activity data analysis. Together, these modules form a comprehensive and innovative approach to prosthetic hand control, promising improved functionality and usability, ultimately enhancing the quality of life for users. In addition to our advanced technology and machine learning algorithms, we prioritize user experience by implementing a user-friendly graphical user interface (GUI) developed with PyQt. The GUI serves as the primary interaction point between the user and the prosthetic hand control system, offering intuitive controls and real-time feedback.
